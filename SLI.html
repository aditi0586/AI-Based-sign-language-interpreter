<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Basic Sign Interpreter Concept</title>
    <!-- Load Tailwind CSS for modern, responsive styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                    },
                    colors: {
                        'primary-blue': '#1D4ED8',
                        'secondary-gray': '#F3F4F6',
                    }
                }
            }
        }
    </script>
    <style>
        /* Custom styling for a clean interface */
        .card {
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        }
    </style>
</head>
<body class="bg-secondary-gray min-h-screen flex items-center justify-center p-4 font-sans">

    <div class="w-full max-w-lg bg-white card rounded-xl p-8">
        <h1 class="text-3xl font-bold text-primary-blue mb-4">
            Sign Language Interpreter Concept
        </h1>
        <p class="text-gray-600 mb-6">
            <span class="font-semibold">BTech 1st Year Project:</span> This code simulates how a machine maps a recognized sign (input) to its English meaning (output).
        </p>

        <!-- Input Section -->
        <div class="mb-6">
            <label for="signInput" class="block text-sm font-medium text-gray-700 mb-2">
                Simulated AI Input (Type a Sign Name):
            </label>
            <input type="text" id="signInput" placeholder="Try: hello, yes, no, or love"
                   class="w-full p-3 border border-gray-300 rounded-lg focus:ring-primary-blue focus:border-primary-blue transition duration-150 ease-in-out">
        </div>

        <button id="interpretButton"
                class="w-full bg-primary-blue text-white py-3 rounded-lg font-semibold hover:bg-blue-700 transition duration-300 ease-in-out">
            Interpret Sign
        </button>

        <!-- Output Section -->
        <div id="outputArea" class="mt-8 p-6 bg-blue-50 border-l-4 border-primary-blue rounded-lg hidden">
            <h2 class="text-xl font-bold text-gray-800 mb-3">Interpretation Result</h2>

            <p class="text-sm font-medium text-gray-600">
                Detected Sign (Input):
                <span id="detectedSign" class="block text-lg font-semibold text-primary-blue"></span>
            </p>

            <p class="text-sm font-medium text-gray-600 mt-3">
                Interpreted Meaning (Output):
                <span id="interpretedMeaning" class="block text-lg font-semibold text-gray-900"></span>
            </p>

            <div class="mt-6">
                <p class="text-sm font-medium text-gray-600 mb-2">
                    Visual Representation (Mockup):
                </p>
                <img id="signImage" alt="Placeholder image for the sign language gesture" class="w-full h-40 object-cover rounded-lg border-2 border-dashed border-gray-300">
            </div>
        </div>

        <!-- Error/Message Box -->
        <div id="messageBox" class="mt-4 p-3 bg-red-100 border-l-4 border-red-500 text-red-700 rounded-lg hidden">
            Sign not recognized in the current dataset.
        </div>

    </div>

    <script>
        // === Core AI Concept: The Knowledge Base (Model) ===
        // In a real AI system, this would be a complex Convolutional Neural Network (CNN)
        // or a Recurrent Neural Network (RNN). Here, it is a simple JavaScript object
        // that maps recognized gestures (keys) to their output (value objects).
        const signMap = {
            "hello": {
                meaning: "Hello, nice to meet you.",
                imgPlaceholder: "https://placehold.co/400x160/2563EB/FFFFFF?text=ASL:+HELLO"
            },
            "yes": {
                meaning: "Confirmation or agreement.",
                imgPlaceholder: "https://placehold.co/400x160/059669/FFFFFF?text=ASL:+YES"
            },
            "no": {
                meaning: "Negation or disagreement.",
                imgPlaceholder: "https://placehold.co/400x160/DC2626/FFFFFF?text=ASL:+NO"
            },
            "love": {
                meaning: "I Love You (ASL gesture).",
                imgPlaceholder: "https://placehold.co/400x160/F59E0B/FFFFFF?text=ASL:+I+LOVE+YOU"
            },
            "thanks": {
                meaning: "Thank you / Gratitude.",
                imgPlaceholder: "https://placehold.co/400x160/7C3AED/FFFFFF?text=ASL:+THANKS"
            },
        };

        // === DOM Element References ===
        const signInput = document.getElementById('signInput');
        const interpretButton = document.getElementById('interpretButton');
        const outputArea = document.getElementById('outputArea');
        const messageBox = document.getElementById('messageBox');
        const detectedSign = document.getElementById('detectedSign');
        const interpretedMeaning = document.getElementById('interpretedMeaning');
        const signImage = document.getElementById('signImage');

        /**
         * The main function simulating the AI interpretation process.
         */
        function interpretSign() {
            // 1. INPUT PREPROCESSING: Get the text and clean it (lowercase, trim spaces).
            // This is similar to normalizing pixel data in a real CNN.
            const rawInput = signInput.value.toLowerCase().trim();

            // Reset UI states
            outputArea.classList.add('hidden');
            messageBox.classList.add('hidden');
            detectedSign.textContent = '';
            interpretedMeaning.textContent = '';
            signImage.src = '';

            if (rawInput === "") {
                messageBox.textContent = "Please enter a sign name to interpret.";
                messageBox.classList.remove('hidden');
                return;
            }

            // 2. MODEL INFERENCE: Look up the sign in the knowledge base (the signMap).
            const interpretation = signMap[rawInput];

            if (interpretation) {
                // 3. POST-PROCESSING & OUTPUT: Sign was recognized. Display results.
                detectedSign.textContent = rawInput.toUpperCase();
                interpretedMeaning.textContent = interpretation.meaning;
                signImage.src = interpretation.imgPlaceholder;
                signImage.alt = Visual representation of the sign: ${rawInput};
                outputArea.classList.remove('hidden');
            } else {
                // 4. ERROR/UNKNOWN: Sign not found in the "model."
                messageBox.textContent = Sign "${rawInput.toUpperCase()}" is not recognized in the current dataset.;
                messageBox.classList.remove('hidden');
            }
        }

        // === Event Listeners (Triggers) ===
        interpretButton.addEventListener('click', interpretSign);

        // Allow interpretation on Enter key press in the input field
        signInput.addEventListener('keypress', (event) => {
            if (event.key === 'Enter') {
                interpretSign();
            }
        });

    </script>
</body>
</html>